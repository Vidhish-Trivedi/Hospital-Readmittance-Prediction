{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Aa9jpQRkiXnh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gc\n",
        "import time\n",
        "\n",
        "device = torch.device('cpu')\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0Pfkjilsi7LL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./processed_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "03iFi3QPituw"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkoG74_zjSB1",
        "outputId": "a2c70581-19f9-4b1b-b1c6-d91f1ed548ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           0    1    2    3    4    5    6    7    8    9    ...  139  140  \\\n",
            "0      47903.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
            "1      38912.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
            "2      21032.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0   \n",
            "3      69762.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
            "4      11955.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0   \n",
            "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "56981  21822.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  2.0   \n",
            "56982  39095.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
            "56983  49046.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  0.0   \n",
            "56984  34998.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  0.0   \n",
            "56985  14295.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  0.0   \n",
            "\n",
            "       141  142  143  144  145   146  147  150  \n",
            "0      2.0  8.0  0.0  0.0  1.0  22.0  4.0    0  \n",
            "1      0.0  8.0  0.0  0.0  1.0  22.0  4.0    0  \n",
            "2      2.0  9.0  0.0  0.0  1.0  22.0  3.0    2  \n",
            "3      0.0  9.0  0.0  0.0  1.0  22.0  1.0    1  \n",
            "4      1.0  9.0  0.0  0.0  2.0  21.0  3.0    0  \n",
            "...    ...  ...  ...  ...  ...   ...  ...  ...  \n",
            "56981  0.0  9.0  0.0  0.0  0.0  23.0  1.0    1  \n",
            "56982  0.0  8.0  1.0  0.0  0.0  22.0  2.0    1  \n",
            "56983  0.0  8.0  0.0  0.0  1.0  22.0  1.0    1  \n",
            "56984  0.0  9.0  0.0  0.0  0.0  23.0  2.0    1  \n",
            "56985  0.0  9.0  0.0  0.0  1.0  22.0  1.0    2  \n",
            "\n",
            "[56986 rows x 149 columns]\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "Y_train = pd.DataFrame(Y_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "Y_test = pd.DataFrame(Y_test)\n",
        "X_train[150] = Y_train[0]\n",
        "X_test[150] = Y_test[0]\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pqQOaaBthuJy"
      },
      "outputs": [],
      "source": [
        "class ANN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_dim: int,\n",
        "        hidden_dim_1: int,\n",
        "        hidden_dim_2: int,\n",
        "        hidden_dim_3: int,\n",
        "        hidden_dim_4: int,\n",
        "        n_classes:int = 3,\n",
        "        dropout: float = 0.3\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(in_features=in_dim, out_features=hidden_dim_1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim_1),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(in_features=hidden_dim_1, out_features=hidden_dim_2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim_2),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(in_features=hidden_dim_2, out_features=hidden_dim_3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim_3),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(in_features=hidden_dim_3, out_features=hidden_dim_4),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim_4),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(in_features=hidden_dim_4, out_features=n_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                x (torch.Tensor): (batch_size, in_dim) the input\n",
        "\n",
        "            Output:\n",
        "                (torch.Tensor): (batch_size, n_classes) the output\n",
        "        \"\"\"\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "_dWjbscZjtUd"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data\n",
        "    ):\n",
        "        self.features = torch.tensor(data.iloc[:, 1:-1].values, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(data.iloc[:, -1].values, dtype=torch.int64)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "cmWnN-kQj2yU"
      },
      "outputs": [],
      "source": [
        "train_dataset = Data(data=X_train)\n",
        "test_dataset = Data(data=X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PQRbYKtmnDjs"
      },
      "outputs": [],
      "source": [
        "train_batchsize = 512\n",
        "val_batchsize = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "CVER7QDknHd7"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=train_batchsize, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=val_batchsize, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "tLjNfir0nNT7"
      },
      "outputs": [],
      "source": [
        "n_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "FcxBBoLAo5tK"
      },
      "outputs": [],
      "source": [
        "model = ANN(\n",
        "    in_dim=147,\n",
        "    hidden_dim_1=147//2,\n",
        "    hidden_dim_2=147//4,\n",
        "    hidden_dim_3=147//8,\n",
        "    hidden_dim_4=147//16\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "htci22b6nRBM"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([8.96, 2.86, 1.85]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "sanity_check=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "oOYPc09ZnXty"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    dataloader,\n",
        "    optimiser\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        x, y = batch[0], batch[1]\n",
        "\n",
        "        output = model(x)\n",
        "        output = nn.Softmax(dim=-1)(output)\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        if sanity_check:\n",
        "            break\n",
        "\n",
        "def validate(\n",
        "    model,\n",
        "    dataloader\n",
        "):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    truths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            x, y = batch[0], batch[1]\n",
        "\n",
        "            output = model(x)\n",
        "            output = nn.Softmax(dim=-1)(output)\n",
        "            loss = loss_fn(output, y)\n",
        "            total_loss += loss.detach().cpu().item()/len(dataloader)\n",
        "\n",
        "            preds = torch.argmax(output, dim=-1)\n",
        "            predictions.extend(preds.cpu())\n",
        "            truths.extend(y.cpu())\n",
        "\n",
        "            if sanity_check:\n",
        "                break\n",
        "\n",
        "    acc = accuracy_score(y_true=truths, y_pred=predictions)\n",
        "    f1 = f1_score(y_true=truths, y_pred=predictions, average='macro')\n",
        "\n",
        "    return total_loss, acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "6QiaIU7SncI_"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    optimiser,\n",
        "):\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"========= EPOCH {epoch} STARTED =========\")\n",
        "        train_epoch(model=model, dataloader=train_dataloader, optimiser=optimiser)\n",
        "\n",
        "        print(f\"========= TRAIN EVALUATION STARTED =========\")\n",
        "        train_val_op = validate(model=model, dataloader=train_dataloader)\n",
        "\n",
        "        print(f\"========= TEST EVALUATION STARTED =========\")\n",
        "        test_val_op = validate(model=model, dataloader=test_dataloader)\n",
        "\n",
        "        print(f\"END OF {epoch} EPOCH\")\n",
        "        print(f\"| Time taken: {time.time() - start_time: 7.3f} |\")\n",
        "        print(f\"| Train Loss: {train_val_op[0]: 7.3f} | Train acc: {train_val_op[1]: 1.5f} | Train f1: {train_val_op[2]: 1.5f} |\")\n",
        "        print(f\"| Test Loss: {test_val_op[0]: 7.3f}  | Test acc: {test_val_op[1]: 1.5f}  | Test f1: {test_val_op[2]: 1.5f}  |\")\n",
        "\n",
        "        if sanity_check:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3B7tFNrnjSc",
        "outputId": "08e551fe-22d7-4ec3-f2d6-e92a70a6ee31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= EPOCH 1 STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 64.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TRAIN EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 84.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TEST EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 59.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF 1 EPOCH\n",
            "| Time taken:  12.197 |\n",
            "| Train Loss:   1.097 | Train acc:  0.38074 | Train f1:  0.31540 |\n",
            "| Test Loss:   1.097  | Test acc:  0.38570  | Test f1:  0.32026  |\n",
            "========= EPOCH 2 STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 92.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TRAIN EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 105.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TEST EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 107.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF 2 EPOCH\n",
            "| Time taken:   9.911 |\n",
            "| Train Loss:   1.096 | Train acc:  0.43948 | Train f1:  0.30827 |\n",
            "| Test Loss:   1.097  | Test acc:  0.43918  | Test f1:  0.30831  |\n",
            "========= EPOCH 3 STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 88.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TRAIN EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 107.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TEST EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 74.98it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF 3 EPOCH\n",
            "| Time taken:   9.920 |\n",
            "| Train Loss:   1.096 | Train acc:  0.45230 | Train f1:  0.31836 |\n",
            "| Test Loss:   1.096  | Test acc:  0.44978  | Test f1:  0.31683  |\n",
            "========= EPOCH 4 STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 89.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TRAIN EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 95.71it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TEST EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 116.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF 4 EPOCH\n",
            "| Time taken:  10.128 |\n",
            "| Train Loss:   1.095 | Train acc:  0.46596 | Train f1:  0.33109 |\n",
            "| Test Loss:   1.096  | Test acc:  0.46438  | Test f1:  0.32902  |\n",
            "========= EPOCH 5 STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 82.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TRAIN EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 99.64it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= TEST EVALUATION STARTED =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 112.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF 5 EPOCH\n",
            "| Time taken:  10.129 |\n",
            "| Train Loss:   1.095 | Train acc:  0.47445 | Train f1:  0.34207 |\n",
            "| Test Loss:   1.095  | Test acc:  0.47617  | Test f1:  0.34293  |\n"
          ]
        }
      ],
      "source": [
        "train_model(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    optimiser=optimiser,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EANk0VbzvUo-",
        "outputId": "40436fa4-1297-4c90-caab-539ac9a54f78"
      },
      "outputs": [],
      "source": [
        "test_data = torch.tensor(X_test.iloc[:10, 1:-1].values, dtype=torch.float32)\n",
        "# print(model.forward(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "tuchDrkyw0W9",
        "outputId": "79839cba-15f7-4ffe-a211-883d4b4e90ad"
      },
      "outputs": [],
      "source": [
        "# Y_test.iloc[:10,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_probs = nn.Softmax(dim=-1)(model(test_data))\n",
        "# print(\"Probabilities:\", output_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3362, 0.3952, 0.2686],\n",
              "        [0.3347, 0.3950, 0.2703],\n",
              "        [0.3061, 0.3847, 0.3092],\n",
              "        [0.3135, 0.2262, 0.4603],\n",
              "        [0.3362, 0.3941, 0.2697],\n",
              "        [0.3069, 0.3814, 0.3117],\n",
              "        [0.3337, 0.3008, 0.3655],\n",
              "        [0.3261, 0.3942, 0.2797],\n",
              "        [0.3247, 0.3294, 0.3459],\n",
              "        [0.3168, 0.3500, 0.3332]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./processed_inference.csv\")\n",
        "X_inference = df.iloc[:, 1:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30530, 147)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_inference.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = torch.tensor(X_inference, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_probs = nn.Softmax(dim=-1)(model(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3336, 0.3009, 0.3656],\n",
              "        [0.3026, 0.1615, 0.5359],\n",
              "        [0.3361, 0.3975, 0.2664],\n",
              "        ...,\n",
              "        [0.3232, 0.3584, 0.3185],\n",
              "        [0.3273, 0.3956, 0.2771],\n",
              "        [0.3197, 0.2682, 0.4121]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_max_idx(l):\n",
        "    return list(l).index(max(l))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_predictions = [get_max_idx(x) for x in output_probs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "392 16937 13201\n"
          ]
        }
      ],
      "source": [
        "print(output_predictions.count(0), output_predictions.count(1), output_predictions.count(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>enc_id</th>\n",
              "      <th>readmission_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86305392</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>394919696</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>164917446</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>178319040</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>253585416</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      enc_id  readmission_id\n",
              "0   86305392               2\n",
              "1  394919696               2\n",
              "2  164917446               1\n",
              "3  178319040               1\n",
              "4  253585416               1"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submit = pd.read_csv(\"./sample_submission.csv\")\n",
        "submit['readmission_id'] = output_predictions\n",
        "submit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    16937\n",
              "2    13201\n",
              "0      392\n",
              "Name: readmission_id, dtype: int64"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submit.to_csv(\"submit_tmp.csv\", index = False)\n",
        "submit['readmission_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
