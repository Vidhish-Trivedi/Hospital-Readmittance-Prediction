{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Networks\n",
        "- Vidhish Trivedi (IMT2021055)\n",
        "- Barath S Narayan (IMT2021524)\n",
        "- Vikas Kalyanapuram (IMT2021040)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing The Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pk1Y_yWEUv1F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\mlds\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading The Data, Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv('./train.csv')\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "\n",
        "train_frequency = train_data['patient_id'].value_counts().to_dict()\n",
        "test_frequency = test_data['patient_id'].value_counts().to_dict()\n",
        "frequency = {}\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] = 0\n",
        "for i in test_frequency:\n",
        "    frequency[i] = 0\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] += train_frequency[i]\n",
        "for i in test_frequency:\n",
        "    frequency[i] += test_frequency[i]\n",
        "\n",
        "train_data['frequency_pid'] = train_data['patient_id'].map(frequency)\n",
        "test_data['frequency_pid'] = test_data['patient_id'].map(frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming 'patient_id' and 'enc_id' are not features for training\n",
        "features = train_data.drop(['patient_id', 'enc_id', 'readmission_id'], axis=1)\n",
        "labels = to_categorical(train_data['readmission_id'])  # One-hot encoding the labels\n",
        "\n",
        "# Handling missing values and encoding categorical variables\n",
        "numeric_features = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = features.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create a column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "\n",
        "# Splitting the training data for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply the preprocessing\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_val = preprocessor.transform(X_val)\n",
        "test_data_processed = preprocessor.transform(test_data.drop(['patient_id', 'enc_id'], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building The Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7u66dl3bU_zS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\mlds\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\mlds\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Building the neural network for multi-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ROc-403VEEg",
        "outputId": "ef6e74c9-55bd-4bce-92f0-747c464fbc5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\mlds\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\mlds\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1781/1781 [==============================] - 9s 4ms/step - loss: 0.7940 - accuracy: 0.6566 - val_loss: 0.7364 - val_accuracy: 0.6939\n",
            "Epoch 2/10\n",
            "1781/1781 [==============================] - 8s 4ms/step - loss: 0.7251 - accuracy: 0.7013 - val_loss: 0.7190 - val_accuracy: 0.7104\n",
            "Epoch 3/10\n",
            "1781/1781 [==============================] - 8s 4ms/step - loss: 0.7053 - accuracy: 0.7134 - val_loss: 0.7101 - val_accuracy: 0.7122\n",
            "Epoch 4/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6940 - accuracy: 0.7191 - val_loss: 0.7043 - val_accuracy: 0.7143\n",
            "Epoch 5/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6840 - accuracy: 0.7217 - val_loss: 0.7052 - val_accuracy: 0.7143\n",
            "Epoch 6/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6769 - accuracy: 0.7248 - val_loss: 0.7007 - val_accuracy: 0.7157\n",
            "Epoch 7/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6735 - accuracy: 0.7245 - val_loss: 0.7126 - val_accuracy: 0.7155\n",
            "Epoch 8/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6661 - accuracy: 0.7272 - val_loss: 0.7131 - val_accuracy: 0.7033\n",
            "Epoch 9/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6600 - accuracy: 0.7295 - val_loss: 0.7171 - val_accuracy: 0.7099\n",
            "Epoch 10/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.6546 - accuracy: 0.7316 - val_loss: 0.7147 - val_accuracy: 0.7157\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6XBHrzRVLl0",
        "outputId": "fbe56a53-a257-4967-b306-de8b016cc4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "955/955 [==============================] - 2s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Making predictions\n",
        "predictions = model.predict(test_data_processed)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "output = pd.DataFrame({'enc_id': test_data['enc_id'], 'readmission_id': predicted_labels})\n",
        "output.to_csv('./output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
